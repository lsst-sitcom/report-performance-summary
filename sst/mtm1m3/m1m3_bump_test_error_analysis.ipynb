{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7762da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check last executions\n",
    "past_time = \"3d\"\n",
    "client_name = \"usdf_efd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c764c4",
   "metadata": {},
   "source": [
    "# M1M3 Bump Test Log Error Analysis and Measured Forces\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook facilitates the analysis of M1M3 force actuator “Bump Test” logs and the visualization of actuator performance through a **Bokeh-based interactive app**.\n",
    "It provides the following features:\n",
    "\n",
    "- **Bump Test Log Analysis:**\n",
    "   Queries and processes recent bump test logs from the EFD to identify failed actuators and extract relevant information, such as deviation type and measured force.\n",
    "\n",
    "- **Execution Details:**\n",
    "   Retrieves and displays script execution logs for the `check_actuators.py` script. Details include:\n",
    "   - Execution start and end times.\n",
    "   - Duration of execution.\n",
    "   - Final process and script statuses.\n",
    "\n",
    "- **Failure Summary Table:**\n",
    "   Summarizes failed actuators with details on failure time, orientation, measured forces, and deviations.\n",
    "   Includes clickable links for further diagnostics of force and following errors of individual actuators.\n",
    "\n",
    "- **Visual Diagnostics:**\n",
    "   Provides comprehensive visualizations, including:\n",
    "   - Plots of positive and negative measured forces for failed actuators.\n",
    "   - A spatial layout showing the distribution of failed actuators on the M1M3 system.\n",
    "\n",
    "This integrated approach enables efficient troubleshooting and performance assessment of M1M3 actuators, supporting both real-time and historical data analysis workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d945a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup and Imports\n",
    "\n",
    "import asyncio\n",
    "import base64\n",
    "import io\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.time import Time, TimeDelta\n",
    "from IPython.display import HTML, display\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import Checkbox, ColumnDataSource, CustomJS, Div, Select\n",
    "from lsst_efd_client import EfdClient\n",
    "from lsst.ts.xml.tables.m1m3 import FATable\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66633d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "### Converting Past Time Strings\n",
    "\n",
    "\n",
    "def convert_to_hours(past_time):\n",
    "    \"\"\"\n",
    "    Convert a string that can be either a number of hours (e.g. '6h')\n",
    "    or a number of days (e.g. '3d') to total number of hours (int).\n",
    "    \"\"\"\n",
    "    match = re.match(r\"(\\d+)([dh]?)\", past_time)\n",
    "    if match:\n",
    "        value, unit = match.groups()\n",
    "        value = int(value)\n",
    "        if unit == \"d\":\n",
    "            return value * 24\n",
    "        else:\n",
    "            return value\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid time format. Please use a format \"\n",
    "            \"like '6h' for hours or '3d' for days.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60054756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Query and Filter Script Queue Logs\n",
    "\n",
    "\n",
    "async def query_script_queue_logs(\n",
    "    start_time_str: str, end_time_str: str, client_name=\"usdf_efd\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Queries the log messages related to the script queue from the EFD.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_time_str : str\n",
    "        Start time in ISO format, e.g. \"2024-11-04T12:00:00\".\n",
    "    end_time_str : str\n",
    "        End time in ISO format, e.g. \"2024-11-04T13:00:00\".\n",
    "    client_name : str, optional\n",
    "        Name of the EFD client. Defaults to \"usdf_efd\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with script queue logs in the given time window.\n",
    "    \"\"\"\n",
    "    # Convert string times to astropy Time\n",
    "    start = Time(start_time_str, format=\"isot\", scale=\"utc\")\n",
    "    end = Time(end_time_str, format=\"isot\", scale=\"utc\")\n",
    "\n",
    "    # Create the EFD client\n",
    "    possible_clients = [\"summit_efd\", \"usdf_efd\"]\n",
    "    if client_name not in possible_clients:\n",
    "        print(f\"Invalid client name. Possible clients: {possible_clients}\")\n",
    "        return None\n",
    "\n",
    "    client = EfdClient(client_name)\n",
    "    script_logs = await client.select_time_series(\n",
    "        topic_name=\"lsst.sal.ScriptQueue.logevent_script\",\n",
    "        fields=\"*\",\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "\n",
    "    return script_logs\n",
    "\n",
    "\n",
    "def filter_and_process_queue_logs(script_logs):\n",
    "    \"\"\"\n",
    "    Filters and processes the script logs DataFrame for a specific script (maintel/m1m3/check_actuators.py).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    script_logs : pd.DataFrame\n",
    "        DataFrame containing the script logs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed DataFrame containing only relevant logs for the check_actuators script.\n",
    "    \"\"\"\n",
    "    processState_mapping = {\n",
    "        0: \"UNKNOWN\",\n",
    "        1: \"LOADING\",\n",
    "        2: \"CONFIGURED\",\n",
    "        3: \"RUNNING\",\n",
    "        4: \"DONE\",\n",
    "        5: \"LOADFAILED\",\n",
    "        6: \"CONFIGURE_FAILED\",\n",
    "        7: \"TERMINATED\",\n",
    "    }\n",
    "\n",
    "    scriptState_mapping = {\n",
    "        0: \"UNKNOWN\",\n",
    "        1: \"UNCONFIGURED\",\n",
    "        2: \"CONFIGURED\",\n",
    "        3: \"RUNNING\",\n",
    "        4: \"PAUSED\",\n",
    "        5: \"ENDING\",\n",
    "        6: \"STOPPING\",\n",
    "        7: \"FAILING\",\n",
    "        8: \"DONE\",\n",
    "        9: \"STOPPED\",\n",
    "        10: \"FAILED\",\n",
    "        11: \"CONFIGURE_FAILED\",\n",
    "    }\n",
    "\n",
    "    # Script path and salIndex we’re focusing on\n",
    "    path = \"maintel/m1m3/check_actuators.py\"\n",
    "    salIndex = 1\n",
    "\n",
    "    df_script_logs = pd.DataFrame(script_logs)\n",
    "\n",
    "    # Filter logs for the specific script path and salIndex\n",
    "    df_filtered_logs = df_script_logs[\n",
    "        (df_script_logs[\"path\"] == path) & (df_script_logs[\"salIndex\"] == salIndex)\n",
    "    ]\n",
    "\n",
    "    # Reindex by private_rcvStamp, convert to UTC\n",
    "    df_filtered_logs = df_filtered_logs.set_index(\"private_rcvStamp\")\n",
    "    df_filtered_logs.index = pd.to_datetime(df_filtered_logs.index, unit=\"s\")\n",
    "    df_filtered_logs.index = df_filtered_logs.index - timedelta(seconds=37)\n",
    "\n",
    "    # Convert all columns starting with 'timestamp' to datetime, also shift TAI->UTC\n",
    "    timestamp_columns = [\n",
    "        col for col in df_filtered_logs.columns if col.startswith(\"timestamp\")\n",
    "    ]\n",
    "    for col in timestamp_columns:\n",
    "        df_filtered_logs[col] = pd.to_datetime(df_filtered_logs[col], unit=\"s\")\n",
    "        df_filtered_logs[col] = df_filtered_logs[col] - timedelta(seconds=37)\n",
    "\n",
    "    # Map numeric process/script states to strings\n",
    "    df_filtered_logs[\"processState_str\"] = df_filtered_logs[\"processState\"].map(\n",
    "        processState_mapping\n",
    "    )\n",
    "    df_filtered_logs[\"scriptState_str\"] = df_filtered_logs[\"scriptState\"].map(\n",
    "        scriptState_mapping\n",
    "    )\n",
    "\n",
    "    # Remove unneeded columns\n",
    "    columns_to_remove = [\n",
    "        \"blockId\",\n",
    "        \"blockSize\",\n",
    "        \"cmdId\",\n",
    "        \"executionId\",\n",
    "        \"private_efdStamp\",\n",
    "        \"private_kafkaStamp\",\n",
    "        \"private_origin\",\n",
    "        \"private_revCode\",\n",
    "        \"private_sndStamp\",\n",
    "        \"private_seqNum\",\n",
    "        \"scriptBlockIndex\",\n",
    "        \"isStandard\",\n",
    "        \"private_identity\",\n",
    "        \"processState\",\n",
    "        \"scriptState\",\n",
    "    ]\n",
    "    df_filtered_logs.drop(columns=columns_to_remove, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # Sort from most recent to oldest\n",
    "    df_filtered_logs.sort_index(ascending=False, inplace=True)\n",
    "\n",
    "    return df_filtered_logs\n",
    "\n",
    "\n",
    "def extract_execution_details(df_check_actuators_log):\n",
    "    \"\"\"\n",
    "    Extracts execution details from the script logs DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_check_actuators_log : pd.DataFrame\n",
    "        DataFrame containing the filtered script logs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing execution times, durations, and final statuses.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store execution details\n",
    "    execution_data = []\n",
    "\n",
    "    # Loop over each unique scriptSalIndex\n",
    "    for script_sal_index in df_check_actuators_log[\"scriptSalIndex\"].unique():\n",
    "        df_sal = df_check_actuators_log[\n",
    "            df_check_actuators_log[\"scriptSalIndex\"] == script_sal_index\n",
    "        ]\n",
    "        df_sal = df_sal.sort_index()  # Ensure chronological order\n",
    "\n",
    "        # Calculate start and end times for each execution\n",
    "        start_time = df_sal[\"timestampProcessStart\"].min()\n",
    "        end_time = df_sal[\"timestampProcessEnd\"].max()\n",
    "\n",
    "        # Get the final process and script status\n",
    "        final_process_status = df_sal[\"processState_str\"].iloc[-1]\n",
    "        final_script_status = df_sal[\"scriptState_str\"].iloc[-1]\n",
    "\n",
    "        execution_data.append(\n",
    "            {\n",
    "                \"scriptSalIndex\": script_sal_index,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"FinalProcessStatus\": final_process_status,\n",
    "                \"FinalScriptStatus\": final_script_status,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df_executions = pd.DataFrame(execution_data)\n",
    "\n",
    "    if not df_executions.empty:\n",
    "        # Calculate duration in minutes\n",
    "        df_executions[\"duration_minutes\"] = (\n",
    "            df_executions[\"end_time\"] - df_executions[\"start_time\"]\n",
    "        ).dt.total_seconds() / 60.0\n",
    "\n",
    "        # Format durations to .2f\n",
    "        df_executions[\"duration_minutes\"] = df_executions[\"duration_minutes\"].apply(\n",
    "            lambda x: \"{:.2f}\".format(x)\n",
    "        )\n",
    "\n",
    "        # Reorder columns\n",
    "        cols = [\n",
    "            \"scriptSalIndex\",\n",
    "            \"start_time\",\n",
    "            \"end_time\",\n",
    "            \"duration_minutes\",\n",
    "            \"FinalProcessStatus\",\n",
    "            \"FinalScriptStatus\",\n",
    "        ]\n",
    "        df_executions = df_executions[cols]\n",
    "\n",
    "        # Sort by start time in descending order\n",
    "        df_executions = df_executions.sort_values(\"start_time\", ascending=False)\n",
    "    else:\n",
    "        print(\"No executions found.\")\n",
    "\n",
    "    return df_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bump Test Queries and Processing\n",
    "\n",
    "### Query Bump Logs\n",
    "\n",
    "\n",
    "async def query_bump_logs(start_date: str, end_date: str, client_name=\"summit_efd\"):\n",
    "    \"\"\"\n",
    "    Queries the log messages related to bump tests from the EFD.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_date : str\n",
    "        Start date of the query in ISO format, e.g. \"2024-11-04T12:00:00\".\n",
    "    end_date : str\n",
    "        End date of the query in ISO format, e.g. \"2024-11-04T13:00:00\".\n",
    "    client_name : str, optional\n",
    "        Name of the EFD client. Defaults to \"summit_efd\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame of bump log messages with the requested fields.\n",
    "    \"\"\"\n",
    "    # Convert strings to datetime, then to astropy Time\n",
    "    start_dt = datetime.fromisoformat(start_date)\n",
    "    end_dt = datetime.fromisoformat(end_date)\n",
    "\n",
    "    possible_clients = [\"summit_efd\", \"usdf_efd\"]\n",
    "    if client_name not in possible_clients:\n",
    "        print(f\"Invalid client name. Possible clients: {possible_clients}\")\n",
    "        return None\n",
    "\n",
    "    client = EfdClient(client_name)\n",
    "\n",
    "    try:\n",
    "        bump_logs = await client.select_time_series(\n",
    "            topic_name=\"lsst.sal.MTM1M3.logevent_logMessage\",\n",
    "            fields=[\"message\"],\n",
    "            start=Time(start_dt.isoformat(), format=\"isot\", scale=\"utc\"),\n",
    "            end=Time(end_dt.isoformat(), format=\"isot\", scale=\"utc\"),\n",
    "        )\n",
    "        return bump_logs\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Error querying data from {start_dt.isoformat()} to {end_dt.isoformat()}: {e}\"\n",
    "        )\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def process_bump_logs(bump_logs, expected_force_range=222, tolerance=5):\n",
    "    \"\"\"\n",
    "    Processes bump log messages to extract relevant information and calculate deviations\n",
    "    from expected forces.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bump_logs : pd.DataFrame\n",
    "        DataFrame containing bump log messages.\n",
    "    expected_force_range : float, optional\n",
    "        Expected magnitude of the applied force.\n",
    "    tolerance : float, optional\n",
    "        Tolerance for the allowed variation in force.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed DataFrame with extracted and calculated data.\n",
    "    \"\"\"\n",
    "    df_filtered_bump_log = bump_logs[\n",
    "        bump_logs[\"message\"].str.contains(\"Failed FA\")\n",
    "    ].copy()\n",
    "\n",
    "    #    if df_filtered_bump_log.empty:\n",
    "    #        print(\"No failed FA messages found in bump logs.\")\n",
    "    #        return pd.DataFrame()\n",
    "\n",
    "    # Extract relevant info from the message\n",
    "    df_filtered_bump_log.loc[:, \"ID\"] = df_filtered_bump_log[\"message\"].str.extract(\n",
    "        r\"FA ID (\\d+)\"\n",
    "    )\n",
    "    orientation_index = df_filtered_bump_log[\"message\"].str.extract(r\"\\((X|Y|Z)(\\d+)\\)\")\n",
    "    df_filtered_bump_log.loc[:, \"Orientation\"] = orientation_index[0]\n",
    "    df_filtered_bump_log.loc[:, \"Index\"] = orientation_index[1]\n",
    "    df_filtered_bump_log.loc[:, \"Error Message\"] = df_filtered_bump_log[\n",
    "        \"message\"\n",
    "    ].str.extract(r\"- (.+)$\")\n",
    "\n",
    "    new_df = df_filtered_bump_log.reset_index().rename(columns={\"index\": \"Time\"})[\n",
    "        [\"Time\", \"ID\", \"Orientation\", \"Index\", \"Error Message\"]\n",
    "    ]\n",
    "\n",
    "    # Extract measured force (ignore disabled actuators with zero force)\n",
    "    new_df[\"MeasuredForce\"] = (\n",
    "        new_df[\"Error Message\"].str.extract(r\"\\(([\\-\\d.]+)\\)\").astype(float)\n",
    "    )\n",
    "    new_df = new_df[new_df[\"MeasuredForce\"] != 0]\n",
    "\n",
    "    # Classify applied force direction\n",
    "    new_df[\"AppliedForceDirection\"] = new_df[\"Error Message\"].apply(\n",
    "        lambda x: \"Positive\" if \"measured force plus\" in x else \"Negative\"\n",
    "    )\n",
    "\n",
    "    # Calculate deviations\n",
    "    upper_limit = expected_force_range\n",
    "    lower_limit = -expected_force_range\n",
    "    new_df[\"Deviation\"] = 0.0\n",
    "\n",
    "    for idx, row in new_df.iterrows():\n",
    "        if row[\"AppliedForceDirection\"] == \"Positive\":\n",
    "            new_df.at[idx, \"Deviation\"] = float(row[\"MeasuredForce\"]) - upper_limit\n",
    "        elif row[\"AppliedForceDirection\"] == \"Negative\":\n",
    "            new_df.at[idx, \"Deviation\"] = float(row[\"MeasuredForce\"]) - lower_limit\n",
    "\n",
    "    # Classify deviation as overshoot or undershoot\n",
    "    def classify_deviation(row):\n",
    "        deviation = abs(row[\"MeasuredForce\"]) - expected_force_range\n",
    "        if deviation > 0:\n",
    "            return \"Overshoot\"\n",
    "        else:\n",
    "            return \"Undershoot\"\n",
    "\n",
    "    new_df[\"DeviationType\"] = new_df.apply(classify_deviation, axis=1)\n",
    "\n",
    "    cols = [\n",
    "        \"Time\",\n",
    "        \"ID\",\n",
    "        \"Orientation\",\n",
    "        \"Index\",\n",
    "        \"AppliedForceDirection\",\n",
    "        \"MeasuredForce\",\n",
    "        \"Deviation\",\n",
    "        \"DeviationType\",\n",
    "    ]\n",
    "    return new_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557890d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from actuator_id to its index in FATable\n",
    "m1m3_actuator_id_index_table = {fa.actuator_id: fa.index for fa in FATable}\n",
    "\n",
    "\n",
    "def get_m1m3_actuator_ids():\n",
    "    \"\"\"Get a list of the M1M3 actuator ids.\"\"\"\n",
    "    return list(m1m3_actuator_id_index_table.keys())\n",
    "\n",
    "\n",
    "def get_xy_position(actuator_list=FATable):\n",
    "    xpos = [actuator.x_position for actuator in actuator_list]\n",
    "    ypos = [actuator.y_position for actuator in actuator_list]\n",
    "    return xpos, ypos\n",
    "\n",
    "\n",
    "def ActuatorsLayout(ax, df, actuator_list=FATable):\n",
    "    \"\"\"\n",
    "    Plot the layout of M1M3 actuators and highlight failed actuators.\n",
    "    \"\"\"\n",
    "    orientation_colors = {\"X\": \"blue\", \"Y\": \"red\", \"Z\": \"green\"}\n",
    "    combined_orientations_colors = {\"XZ\": \"orange\", \"YZ\": \"black\"}\n",
    "\n",
    "    ax.set_xlabel(\"X position (m)\")\n",
    "    ax.set_ylabel(\"Y position (m)\")\n",
    "    ax.set_title(\"Failures Distribution\", fontsize=12)\n",
    "\n",
    "    ids = get_m1m3_actuator_ids()\n",
    "    xpos, ypos = get_xy_position(actuator_list)\n",
    "\n",
    "    actuator_orientations = defaultdict(set)\n",
    "    for actuator_id, orientation in zip(df[\"ID\"], df[\"Orientation\"]):\n",
    "        actuator_orientations[int(actuator_id)].add(orientation)\n",
    "\n",
    "    ax.plot(xpos, ypos, \"o\", ms=14, color=\"blue\", alpha=0.05, mec=\"red\")\n",
    "    for l, x, y in zip(ids, xpos, ypos):\n",
    "        ax.annotate(\n",
    "            l,\n",
    "            (x, y),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(-5.5, -2),\n",
    "            color=\"blue\",\n",
    "            size=\"xx-small\",\n",
    "        )\n",
    "\n",
    "    for actuator_id, orientations in actuator_orientations.items():\n",
    "        if actuator_id in m1m3_actuator_id_index_table:\n",
    "            index = m1m3_actuator_id_index_table[actuator_id]\n",
    "            if len(orientations) > 1:\n",
    "                key = \"\".join(sorted(orientations))\n",
    "                color = combined_orientations_colors.get(key, \"gray\")\n",
    "            else:\n",
    "                key = list(orientations)[0]\n",
    "                color = orientation_colors.get(key, \"gray\")\n",
    "            ax.scatter(\n",
    "                xpos[index],\n",
    "                ypos[index],\n",
    "                marker=\"o\",\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=color,\n",
    "                s=250,\n",
    "                alpha=0.5,\n",
    "                linewidths=2,\n",
    "            )\n",
    "\n",
    "    # Legend\n",
    "    unique_orientations = {\n",
    "        ori\n",
    "        for orientations in actuator_orientations.values()\n",
    "        if len(orientations) == 1\n",
    "        for ori in orientations\n",
    "    }\n",
    "    combined_orientations = {\n",
    "        \"\".join(sorted(orientations))\n",
    "        for orientations in actuator_orientations.values()\n",
    "        if len(orientations) > 1\n",
    "    }\n",
    "\n",
    "    for orientation in unique_orientations:\n",
    "        ax.scatter(\n",
    "            [],\n",
    "            [],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"None\",\n",
    "            s=10,\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=orientation_colors.get(orientation, \"gray\"),\n",
    "            alpha=0.9,\n",
    "            label=f\"Orientation {orientation}\",\n",
    "        )\n",
    "\n",
    "    for combined_orientation in combined_orientations:\n",
    "        ax.scatter(\n",
    "            [],\n",
    "            [],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"None\",\n",
    "            s=10,\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=combined_orientations_colors.get(combined_orientation, \"gray\"),\n",
    "            alpha=0.5,\n",
    "            label=f\"Orientation {combined_orientation}\",\n",
    "        )\n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "def plot_deviations_and_layout(\n",
    "    df_failures, fig, actuator_list=FATable, expected_force=222, tolerance=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a single figure with:\n",
    "      - Two subplots stacked vertically (Positive, Negative) on the left,\n",
    "      - One subplot on the right for the actuator layout, with a square aspect.\n",
    "\n",
    "    Assumes df_failures already has columns:\n",
    "      'ID', 'DeviationType', 'AppliedForceDirection', 'MeasuredForce',\n",
    "      and any others needed (e.g. 'Orientation').\n",
    "    \"\"\"\n",
    "\n",
    "    if df_failures.empty:\n",
    "        print(\"The DataFrame is empty. Nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert ID to string for plotting on x-axis\n",
    "    df_failures[\"ID\"] = df_failures[\"ID\"].astype(str)\n",
    "    sorted_ids = df_failures[\"ID\"].sort_values().unique()\n",
    "\n",
    "    # Dictionary for how each deviation type should look\n",
    "    deviation_styles = {\n",
    "        \"Overshoot\": {\"color\": \"red\", \"marker\": \"o\"},\n",
    "        \"Undershoot\": {\"color\": \"green\", \"marker\": \"s\"},\n",
    "    }\n",
    "\n",
    "    # Map each ID to a position on the x-axis\n",
    "    id_to_position = {id_: pos for pos, id_ in enumerate(sorted_ids)}\n",
    "    df_failures[\"ID_Pos\"] = df_failures[\"ID\"].map(id_to_position)\n",
    "\n",
    "    # Create the GridSpec layout within the provided figure\n",
    "    gs = gridspec.GridSpec(\n",
    "        nrows=2,\n",
    "        ncols=2,\n",
    "        width_ratios=[2, 1],  # left is twice as wide as right\n",
    "        height_ratios=[2, 2],\n",
    "        figure=fig,\n",
    "    )\n",
    "\n",
    "    # Left column subplots\n",
    "    ax_positive = fig.add_subplot(gs[0, 0])\n",
    "    ax_negative = fig.add_subplot(gs[1, 0], sharex=ax_positive)\n",
    "    # Right column subplot (spans both rows)\n",
    "    ax_layout = fig.add_subplot(gs[:, 1])\n",
    "\n",
    "    # Separate the DataFrame\n",
    "    df_positive = df_failures[df_failures[\"AppliedForceDirection\"] == \"Positive\"]\n",
    "    df_negative = df_failures[df_failures[\"AppliedForceDirection\"] == \"Negative\"]\n",
    "\n",
    "    # --- Subplot: Positive Forces ---\n",
    "    for dev_type, group in df_positive.groupby(\"DeviationType\"):\n",
    "        style = deviation_styles.get(dev_type, {\"color\": \"gray\", \"marker\": \"o\"})\n",
    "        ax_positive.scatter(\n",
    "            group[\"ID_Pos\"],\n",
    "            group[\"MeasuredForce\"],\n",
    "            c=style[\"color\"],\n",
    "            marker=style[\"marker\"],\n",
    "            alpha=0.7,\n",
    "            label=f\"Positive - {dev_type}\",\n",
    "        )\n",
    "\n",
    "    # Expected line & tolerance range for Positive\n",
    "    ax_positive.axhline(expected_force, color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "    ax_positive.fill_between(\n",
    "        [-1, len(sorted_ids)],\n",
    "        expected_force - tolerance,\n",
    "        expected_force + tolerance,\n",
    "        color=\"gray\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax_positive.set_ylabel(\"Measured Force (N)\")\n",
    "    ax_positive.set_title(\"Measured Forces (Positive)\")\n",
    "\n",
    "    # Add ylim\n",
    "    max_force = df_positive[\"MeasuredForce\"].max()\n",
    "    min_force = df_positive[\"MeasuredForce\"].min()\n",
    "    if max_force > expected_force + tolerance:\n",
    "        ax_positive.set_ylim(top=max_force + 15)\n",
    "    else:\n",
    "        ax_positive.set_ylim(top=expected_force + tolerance + 15)\n",
    "\n",
    "    if min_force < expected_force - tolerance:\n",
    "        ax_positive.set_ylim(bottom=min_force - 15)\n",
    "    else:\n",
    "        ax_positive.set_ylim(bottom=expected_force - tolerance - 15)\n",
    "\n",
    "    # --- Subplot: Negative Forces ---\n",
    "    for dev_type, group in df_negative.groupby(\"DeviationType\"):\n",
    "        style = deviation_styles.get(dev_type, {\"color\": \"gray\", \"marker\": \"o\"})\n",
    "        ax_negative.scatter(\n",
    "            group[\"ID_Pos\"],\n",
    "            group[\"MeasuredForce\"],\n",
    "            c=style[\"color\"],\n",
    "            marker=style[\"marker\"],\n",
    "            alpha=0.7,\n",
    "            label=f\"Negative - {dev_type}\",\n",
    "        )\n",
    "\n",
    "    ax_negative.axhline(-expected_force, color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "    ax_negative.fill_between(\n",
    "        [-1, len(sorted_ids)],\n",
    "        -(expected_force + tolerance),\n",
    "        -(expected_force - tolerance),\n",
    "        color=\"gray\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ax_negative.set_xlabel(\"FA ID\")\n",
    "    ax_negative.set_ylabel(\"Measured Force (N)\")\n",
    "    ax_negative.set_title(\"Measured Forces (Negative)\")\n",
    "\n",
    "    # Add ylim like in the positive graph, but take into account that this in the negative side\n",
    "    max_force = df_negative[\"MeasuredForce\"].max()\n",
    "    min_force = df_negative[\"MeasuredForce\"].min()\n",
    "    if max_force > -expected_force + tolerance:\n",
    "        ax_negative.set_ylim(top=max_force + 15)\n",
    "    else:\n",
    "        ax_negative.set_ylim(top=-expected_force + tolerance + 15)\n",
    "\n",
    "    if min_force < -expected_force - tolerance:\n",
    "        ax_negative.set_ylim(bottom=min_force - 15)\n",
    "    else:\n",
    "        ax_negative.set_ylim(bottom=-expected_force - tolerance - 15)\n",
    "\n",
    "    # Set x-ticks only on the bottom subplot\n",
    "    ax_negative.set_xticks(range(len(sorted_ids)))\n",
    "    ax_negative.set_xticklabels(sorted_ids, rotation=45, ha=\"center\")\n",
    "\n",
    "    # --- Build a custom legend for the top subplot ---\n",
    "    legend_handles = []\n",
    "\n",
    "    # 1) Add markers for Deviation Types\n",
    "    for dev_type, style in deviation_styles.items():\n",
    "        legend_handles.append(\n",
    "            Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                marker=style[\"marker\"],\n",
    "                color=\"w\",\n",
    "                label=dev_type,\n",
    "                markerfacecolor=style[\"color\"],\n",
    "                markersize=8,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 2) Add line handles for Expected Force + Tolerance\n",
    "    expected_line = Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        color=\"gray\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Expected Force = {expected_force} ± {tolerance} N\",\n",
    "    )\n",
    "\n",
    "    legend_handles.extend([expected_line])\n",
    "\n",
    "    # Move legend outside of the graph and make it more compact\n",
    "    ax_positive.legend(\n",
    "        handles=legend_handles,\n",
    "        loc=\"upper left\",\n",
    "        fontsize=\"small\",\n",
    "        borderaxespad=0,\n",
    "        frameon=True,\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: Layout of Actuators ---\n",
    "    ActuatorsLayout(ax_layout, df_failures, actuator_list=actuator_list)\n",
    "\n",
    "    # Ensure the layout subplot is square\n",
    "    ax_layout.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    # Final adjustments\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd608ae2",
   "metadata": {},
   "source": [
    "## Getting Past Executions\n",
    "\n",
    "### Script Queue Logs\n",
    "Here we create a summary of the last few executions of the `check_actuators.py` script for the selected `past_time` and `client_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_hours = convert_to_hours(past_time)\n",
    "\n",
    "now_utc = datetime.utcnow()\n",
    "end_dt = now_utc\n",
    "start_dt = now_utc - timedelta(hours=past_hours)\n",
    "\n",
    "start_str = start_dt.isoformat()\n",
    "end_str = end_dt.isoformat()\n",
    "\n",
    "script_logs = await query_script_queue_logs(start_str, end_str, client_name=client_name)\n",
    "script_logs_processed = filter_and_process_queue_logs(script_logs)\n",
    "df_executions = extract_execution_details(script_logs_processed)\n",
    "\n",
    "# Display executions summary\n",
    "if df_executions.empty:\n",
    "    print(\"No executions found in the last {:.1f} days.\".format(past_hours / 24.0))\n",
    "else:\n",
    "    print(\"Executions found in the last {:.1f} days.\".format(past_hours / 24.0))\n",
    "    display(df_executions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791396a6",
   "metadata": {},
   "source": [
    "### Interactive Bokeh App to Query and Plot Bump Test Failures\n",
    "\n",
    "In this section, an interactive **Bokeh-based app** is provided to guide you through the bump test log analysis:\n",
    "\n",
    "1. **`SalIndex` Dropdown:**\n",
    "   Allows you to select a specific script execution (identified by its `SalIndex`) within the provided time range.\n",
    "   Once selected, the app retrieves the associated execution details (start time, end time, duration, etc.).\n",
    "   Only executions within the selected time range are displayed.\n",
    "\n",
    "2. **Execution Summary:**\n",
    "   Upon selecting a `SalIndex`, the notebook displays detailed execution information, including:\n",
    "   - Start and end times of the execution.\n",
    "   - Execution duration.\n",
    "   - Process and script statuses.\n",
    "\n",
    "3. **Failure Summary Table:**\n",
    "   If failed actuators are detected, the app shows a table summarizing:\n",
    "   - The time of failure.\n",
    "   - Actuator ID.\n",
    "   - Orientation and force details (measured force, deviation, and deviation type).\n",
    "   - A clickable link to detailed plots for individual actuators.\n",
    "\n",
    "4. **“Plot Measured Forces” Checkbox:**\n",
    "   Toggles the visualization of measured forces for all failed actuators. When enabled, the notebook displays:\n",
    "   - A set of plots showing positive and negative force deviations for the failed actuators.\n",
    "   - A layout plot indicating the spatial distribution of failed actuators on the M1M3 system.\n",
    "\n",
    "5. **Dynamic Visualization:**\n",
    "   The app dynamically updates the table, execution summary, and plots based on the selected `SalIndex` and the checkbox state.\n",
    "   This streamlined interface allows users to quickly explore and analyze bump test logs.\n",
    "\n",
    "---\n",
    "\n",
    "**<span style=\"color: red;\">Note:</span>**\n",
    "The expected measured force for each bump test is **222 N** with a tolerance of **±5 N**. Deviations beyond this range are classified as either **overshoot** or **undershoot** based on the measured force.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions, build_all_data, and launch Bokeh app\n",
    "\n",
    "# Initialize Bokeh to display plots in the notebook\n",
    "output_notebook()\n",
    "\n",
    "# ---------------------------\n",
    "# Define Helper Functions\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "def make_fa_link(fa_id, t_start_str, t_end_str):\n",
    "    \"\"\"\n",
    "    Create an HTML link to the detail notebook for a given FA ID.\n",
    "\n",
    "    Parameters:\n",
    "    - fa_id: int or str, Force Actuator ID.\n",
    "    - t_start_str: str, ISO-formatted start time.\n",
    "    - t_end_str: str, ISO-formatted end time.\n",
    "\n",
    "    Returns:\n",
    "    - str: HTML <a> tag linking to the detail notebook.\n",
    "    \"\"\"\n",
    "    detail_url = (\n",
    "        \"https://usdf-rsp-dev.slac.stanford.edu/times-square/github/lsst-sitcom/\"\n",
    "        \"reports-performance-summary/sst/mtm1m3/Bump_test_individual_force_actuator\"\n",
    "        f\"?t_start={t_start_str}&t_end={t_end_str}&id={fa_id}&ts_hide_code=1\"\n",
    "    )\n",
    "    return f'<a href=\"{detail_url}\" target=\"_blank\">{fa_id}</a>'\n",
    "\n",
    "\n",
    "def mpl_fig_to_base64_png(fig):\n",
    "    \"\"\"\n",
    "    Convert a Matplotlib figure to a base64-encoded PNG <img> tag.\n",
    "    \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "    buf.seek(0)\n",
    "    b64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    buf.close()  # Close the buffer to release resources\n",
    "    return b64\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Define build_all_data Function\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "async def build_all_data(df_executions, client_name):\n",
    "    \"\"\"\n",
    "    For each SalIndex in df_executions:\n",
    "      1) Query bump logs.\n",
    "      2) Process bump logs.\n",
    "      3) Create clickable links for FA IDs.\n",
    "      4) Generate Matplotlib plots and convert to base64.\n",
    "\n",
    "    Parameters:\n",
    "    - df_executions: pandas DataFrame with execution details.\n",
    "    - client_name: str, name of the EFD client.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Keyed by SalIndex, each containing info_html, df_html, plot_html.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "\n",
    "    for _, row in df_executions.iterrows():\n",
    "        sal_idx = row[\"scriptSalIndex\"]\n",
    "        t_start = row[\"start_time\"]\n",
    "        t_end = row[\"end_time\"]\n",
    "        duration = row[\"duration_minutes\"]\n",
    "        final_proc = row[\"FinalProcessStatus\"]\n",
    "        final_script = row[\"FinalScriptStatus\"]\n",
    "\n",
    "        start_str = t_start.isoformat()\n",
    "        end_str = t_end.isoformat()\n",
    "\n",
    "        # Adjust start time by subtracting 10 days for the link\n",
    "        adjusted_start = Time(t_start).datetime - timedelta(days=10)\n",
    "        adjusted_start_str = adjusted_start.isoformat()\n",
    "\n",
    "        # 1) Query bump logs\n",
    "        bump_logs = await query_bump_logs(start_str, end_str, client_name)\n",
    "        if bump_logs.empty:\n",
    "            all_data[sal_idx] = {\n",
    "                \"info_html\": (\n",
    "                    f\"<b>SalIndex {sal_idx}</b><br>\"\n",
    "                    f\"No bump logs found.<br>\"\n",
    "                    f\"Start: {t_start}, End: {t_end}, Duration: {duration} min\"\n",
    "                ),\n",
    "                \"df_html\": \"<p>No logs found.</p>\",\n",
    "                \"plot_html\": \"\",\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        # 2) Process bump logs\n",
    "        df_fail = process_bump_logs(bump_logs)\n",
    "        if df_fail.empty:\n",
    "            all_data[sal_idx] = {\n",
    "                \"info_html\": (\n",
    "                    f\"<b>SalIndex {sal_idx}</b><br>\"\n",
    "                    f\"No failed actuators found.<br>\"\n",
    "                    f\"Start: {t_start}, End: {t_end}, Duration: {duration} min\"\n",
    "                ),\n",
    "                \"df_html\": \"<p>No failed actuators.</p>\",\n",
    "                \"plot_html\": \"\",\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        # 3) Create clickable links for FA IDs\n",
    "        if \"ID\" in df_fail.columns and \"Orientation\" in df_fail.columns:\n",
    "            df_fail[\"Force_Error_Plots_Link\"] = df_fail.apply(\n",
    "                lambda r: make_fa_link(r[\"ID\"], adjusted_start_str, end_str), axis=1\n",
    "            )\n",
    "            # Ensure 'ID' remains for plotting\n",
    "        else:\n",
    "            df_fail[\"Force_Error_Plots_Link\"] = \"\"\n",
    "\n",
    "        # 4) Convert DataFrame to HTML with clickable links\n",
    "        df_html = df_fail.to_html(escape=False, index=False)\n",
    "\n",
    "        # 5) Generate the plot and convert to base64\n",
    "        fig = plt.figure(figsize=(14, 5))\n",
    "        plot_deviations_and_layout(df_fail, fig, actuator_list=FATable)\n",
    "        plot_html = mpl_fig_to_base64_png(fig)\n",
    "        plt.close(fig)  # Prevent automatic display\n",
    "\n",
    "        # 6) Create informational HTML\n",
    "        info_html = (\n",
    "            f\"<b>SalIndex {sal_idx}</b><br>\"\n",
    "            f\"Start: {t_start}, End: {t_end}, Duration: {duration} min<br>\"\n",
    "            f\"ProcessStatus: {final_proc}, ScriptStatus: {final_script}\"\n",
    "        )\n",
    "\n",
    "        # 7) Store in the dictionary\n",
    "        all_data[sal_idx] = {\n",
    "            \"info_html\": info_html,\n",
    "            \"df_html\": df_html,\n",
    "            \"plot_html\": plot_html,\n",
    "        }\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Build all_results by Processing df_executions\n",
    "# ---------------------------\n",
    "\n",
    "# Execute the build_all_data function to populate all_results\n",
    "all_results = await build_all_data(df_executions, client_name)\n",
    "\n",
    "# ---------------------------\n",
    "# Convert all_results to a DataFrame for Bokeh\n",
    "# ---------------------------\n",
    "\n",
    "if all_results:\n",
    "    df_bokeh = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"SalIndex\": sal_idx,\n",
    "                \"info_html\": data[\"info_html\"],\n",
    "                \"df_html\": data[\"df_html\"],\n",
    "                \"plot_html\": data[\"plot_html\"],\n",
    "            }\n",
    "            for sal_idx, data in all_results.items()\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    # Handle the case where all_results is empty\n",
    "    df_bokeh = pd.DataFrame(columns=[\"SalIndex\", \"info_html\", \"df_html\", \"plot_html\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Create a ColumnDataSource from the DataFrame\n",
    "# ---------------------------\n",
    "\n",
    "source = ColumnDataSource(df_bokeh)\n",
    "\n",
    "# ---------------------------\n",
    "# Define the Bokeh Widgets\n",
    "# ---------------------------\n",
    "\n",
    "# Define the SalIndex dropdown using Bokeh's Select widget\n",
    "sal_index_selector = Select(\n",
    "    title=\"SalIndex:\",\n",
    "    value=df_bokeh[\"SalIndex\"].iloc[-1]\n",
    "    if not df_bokeh.empty\n",
    "    else None,  # Default to the last SalIndex\n",
    "    options=[\n",
    "        (sal_idx, f\"{sal_idx}\") for sal_idx in sorted(df_bokeh[\"SalIndex\"].tolist())\n",
    "    ],\n",
    "    width=200,\n",
    ")\n",
    "\n",
    "# Define the checkbox to toggle plot visibility using Bokeh's Checkbox widget\n",
    "show_forces_checkbox = Checkbox(label=\"Plot measured forces\", active=True, width=200)\n",
    "\n",
    "# Define Div widgets for displaying informational text, summary table, and plot\n",
    "info_div = Div(text=\"<b>Select a SalIndex to see details.</b>\", width=800, height=100)\n",
    "\n",
    "table_div = Div(\n",
    "    text=\"\", width=1200, styles={\"overflow\": \"auto\", \"padding\": \"10px\"}\n",
    ")  # Initially empty\n",
    "\n",
    "plot_div = Div(\n",
    "    text=\"\", styles={\"overflow\": \"auto\", \"padding\": \"10px\"}\n",
    ")  # Initially empty\n",
    "\n",
    "# ---------------------------\n",
    "# Define the CustomJS Callbacks\n",
    "# ---------------------------\n",
    "\n",
    "# Define the CustomJS callback for the SalIndex Select widget\n",
    "select_callback = CustomJS(\n",
    "    args=dict(\n",
    "        source=source,\n",
    "        info_div=info_div,\n",
    "        table_div=table_div,\n",
    "        plot_div=plot_div,\n",
    "        checkbox=show_forces_checkbox,\n",
    "    ),\n",
    "    code=\"\"\"\n",
    "    // Get the selected SalIndex\n",
    "    var data = source.data;\n",
    "    var sal_idx = cb_obj.value;\n",
    "    var show_plot = checkbox.active;\n",
    "\n",
    "    // Find the index of the selected SalIndex\n",
    "    var index = data['SalIndex'].indexOf(sal_idx);\n",
    "\n",
    "    if(index === -1){\n",
    "        // If SalIndex not found, clear the Divs\n",
    "        info_div.text = \"<b>Select a SalIndex to see details.</b>\";\n",
    "        table_div.text = \"\";\n",
    "        plot_div.text = \"\";\n",
    "    }\n",
    "    else{\n",
    "        // Update the informational Div\n",
    "        info_div.text = data['info_html'][index];\n",
    "\n",
    "        // Update the summary table Div\n",
    "        table_div.text = data['df_html'][index];\n",
    "\n",
    "        // Update the plot Div based on the checkbox state\n",
    "        if(show_plot && data['plot_html'][index]){\n",
    "            plot_div.text = \"<img src='data:image/png;base64,\" + data['plot_html'][index] + \"'/>\";\n",
    "        }\n",
    "        else{\n",
    "            plot_div.text = \"\";\n",
    "        }\n",
    "    }\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "# Define the CustomJS callback for the Checkbox widget\n",
    "checkbox_callback = CustomJS(\n",
    "    args=dict(\n",
    "        source=source,\n",
    "        info_div=info_div,\n",
    "        table_div=table_div,\n",
    "        plot_div=plot_div,\n",
    "        sal_select=sal_index_selector,\n",
    "    ),\n",
    "    code=\"\"\"\n",
    "    // Get the current SalIndex\n",
    "    var data = source.data;\n",
    "    var sal_idx = sal_select.value;\n",
    "    var show_plot = cb_obj.active;\n",
    "\n",
    "    // Find the index of the selected SalIndex\n",
    "    var index = data['SalIndex'].indexOf(sal_idx);\n",
    "\n",
    "    if (index === -1) {\n",
    "        // If SalIndex not found, do nothing\n",
    "        return;\n",
    "    } else {\n",
    "        // Update the plot Div based on the checkbox state\n",
    "        if (show_plot && data['plot_html'][index]) {\n",
    "            // Ensure proper formatting of the <img> tag\n",
    "            plot_div.text = \"<img src='data:image/png;base64,\" + data['plot_html'][index].trim() +\n",
    "                            \"' style='max-width: 80%; height: auto; display: block; margin: 0 auto;' />\";\n",
    "        } else {\n",
    "            plot_div.text = \"\";\n",
    "        }\n",
    "\n",
    "        // Adjust spacing\n",
    "        plot_div.style.marginTop = \"10px\";\n",
    "        plot_div.style.marginBottom = \"0px\";\n",
    "    }\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Attach the Callbacks to the Widgets\n",
    "# ---------------------------\n",
    "\n",
    "# Attach the CustomJS callback to the SalIndex Select widget\n",
    "sal_index_selector.js_on_change(\"value\", select_callback)\n",
    "\n",
    "# Attach the CustomJS callback to the Checkbox widget\n",
    "show_forces_checkbox.js_on_change(\"active\", checkbox_callback)\n",
    "\n",
    "# ---------------------------\n",
    "# Initialize the Display\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "def initialize_display():\n",
    "    \"\"\"\n",
    "    Initializes the Div widgets based on the current widget states.\n",
    "    \"\"\"\n",
    "    if not df_bokeh.empty and sal_index_selector.value is not None:\n",
    "        sal_idx = sal_index_selector.value\n",
    "        index = df_bokeh[\"SalIndex\"].tolist().index(sal_idx)\n",
    "        info_div.text = df_bokeh[\"info_html\"].iloc[index]\n",
    "        table_div.text = df_bokeh[\"df_html\"].iloc[index]\n",
    "        if show_forces_checkbox.active and df_bokeh[\"plot_html\"].iloc[index]:\n",
    "            plot_div.text = f\"<img src='data:image/png;base64,{df_bokeh['plot_html'].iloc[index]}'/>\"\n",
    "    else:\n",
    "        info_div.text = \"<b>Select a SalIndex to see details.</b>\"\n",
    "        table_div.text = \"\"\n",
    "        plot_div.text = \"\"\n",
    "\n",
    "\n",
    "# Call the initialization function to set up the initial display\n",
    "initialize_display()\n",
    "\n",
    "# ---------------------------\n",
    "# Arrange and Display the Layout\n",
    "# ---------------------------\n",
    "\n",
    "# Arrange the widgets and Divs in the layout\n",
    "layout = column(\n",
    "    row(sal_index_selector, show_forces_checkbox),\n",
    "    info_div,\n",
    "    table_div,\n",
    "    plot_div,\n",
    "    spacing=0,  # Reduce the default spacing\n",
    "    sizing_mode=\"stretch_width\",  # Optional: Adjust width dynamically\n",
    ")\n",
    "\n",
    "# Display the layout\n",
    "show(layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsst-scipipe-9.0.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
